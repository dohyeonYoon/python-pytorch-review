{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"데이터 불러오기.ipynb","provenance":[],"authorship_tag":"ABX9TyPR3swrbM5e/iodbhbfv0AF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f637a71091e54695934dca4c3464596e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ae8c05786b5242f4844eab289a5b6b25","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_04e09ff534e44161ab98d8e03e1df9d4","IPY_MODEL_7961a9d779c04e9793d99cec983d5574"]}},"ae8c05786b5242f4844eab289a5b6b25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"04e09ff534e44161ab98d8e03e1df9d4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_baeb7ec00fc44002862a6339ab424d57","_dom_classes":[],"description":"","_model_name":"FloatProgressModel","bar_style":"success","max":170498071,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":170498071,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_b0fb12e9c2a2448381b8cc1d7d3e10d8"}},"7961a9d779c04e9793d99cec983d5574":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_acdfe5e1d4314a5383176717391e9c00","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 170499072/? [03:46&lt;00:00, 754414.48it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_818486eac7b9408ba80e62357508cd9c"}},"baeb7ec00fc44002862a6339ab424d57":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"b0fb12e9c2a2448381b8cc1d7d3e10d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"acdfe5e1d4314a5383176717391e9c00":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"818486eac7b9408ba80e62357508cd9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"Iv_be0q313K_"},"source":["# 3. 데이터 불러오기\n","\n","딥러닝을 포함한 머신러닝의 근원은 데이터다. 따라서 데이터의 수집,가공,사용 방법에 따라 모델 성능이 크게 달라질 수 있으며 데이터의 형태는 매우 다양하기 떄문에 데이터를 잘 불러오는 것은 가장 중요한 단계 중 하나다. "]},{"cell_type":"code","metadata":{"id":"WoFxgotx12Fp"},"source":["import torch \n","import torchvision \n","import torchvision.transforms as tr  #이미지 전처리 기능\n","from torch.utils.data import DataLoader, Dataset # 데이터를 모델에 사용할 수 있도록 정리해 주는 라이브러리 \n","import numpy as np "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PMAjqTGq2XyH"},"source":["# 3.1 파이토치 제공 데이터 사용"]},{"cell_type":"code","metadata":{"id":"ONntewvG2Qxm"},"source":["# https://pytorch.org/docs/stable/torchvision/transforms.html 다양한 전처리 방법 공부 \n","\n","transf = tr.Compose([tr.Resize(16), tr.ToTensor()]) # 16x16으로 이미지 크기 변환 후 텐서 타입으로 변환한다. \n","   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":120,"referenced_widgets":["f637a71091e54695934dca4c3464596e","ae8c05786b5242f4844eab289a5b6b25","04e09ff534e44161ab98d8e03e1df9d4","7961a9d779c04e9793d99cec983d5574","baeb7ec00fc44002862a6339ab424d57","b0fb12e9c2a2448381b8cc1d7d3e10d8","acdfe5e1d4314a5383176717391e9c00","818486eac7b9408ba80e62357508cd9c"]},"id":"dpVbAmT08m72","executionInfo":{"status":"ok","timestamp":1627875728554,"user_tz":-540,"elapsed":16706,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"d21b7db0-da26-4c08-f7e2-915529a07fda"},"source":["# torchvision.datasets에서 제공하는 CIFAR10 데이터셋 불러오기\n","# root에는 다운로드 받을 경로를 입력하기\n","# train = True 이면 학습 데이터를 불러오고 False이면 테스트 데이터를 불러온다\n","# 미리 선언한 전처리를 사용하기 위해 transform=transf 작성\n","\n","trainset = torchvision.datasets.CIFAR10(root = './data', train=True, download=True, transform=transf)\n","testset = torchvision.datasets.CIFAR10(root = './data', train=False, download=True, transform=transf)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f637a71091e54695934dca4c3464596e","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Extracting ./data/cifar-10-python.tar.gz to ./data\n","Files already downloaded and verified\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E2yOIoAt9Bl7","executionInfo":{"status":"ok","timestamp":1627875961364,"user_tz":-540,"elapsed":388,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"cfd512e6-56c6-45b8-b139-4e71c96283a0"},"source":["# 일반적으로 데이터셋은 이미지와 라벨이 동시에 들어있는 튜플형태이다 (이미지, 라벨)\n","# traninset[0]은 학습 데이터의 이미지 한장과 라벨 하나가 저장되어 있다.\n","# 즉 trainset[0][0]은 이미지이고 trainset[0][1]은 라벨이다. \n","\n","print(trainset[0][0].size())\n","\n","trainset "],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([3, 16, 16])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1HHKN8AZ-Erc"},"source":["일반적인 컬러 사진은 RGB 이미지이기 떄문에 채널이 3개이고 (너비)x(높이)x(채널 수) 로 크기가 표현된다. \n","\n","하지만 파이토치에서는 이미지 한 장이 (채널 수) x (너비) x (높이) 로 표현되니 주의! "]},{"cell_type":"code","metadata":{"id":"sugBW7JN97xt"},"source":["# DataLoader는 데이터를 미니 배치 형태로 만들어 준다.\n","# 따라서 배치 사이즈 및 셔플 여부 등을 선택해야 한다.\n","\n","trainloader = DataLoader(trainset, batch_size=50, shuffle= True)\n","testloader = DataLoader(testset, batch_size=50, shuffle= False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7pPvtBE_E-8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1627878010898,"user_tz":-540,"elapsed":412,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"eb84afd1-4398-4600-ca82-e720f8ca4302"},"source":["len (trainloader)\n","\n","# CIFAR10의 학습 이미지는 50,000장이고 배치사이즈가 50장이므로 배치갯수는 1000개 이다 "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1000"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vsbwb8b_Fnm1","executionInfo":{"status":"ok","timestamp":1627878070382,"user_tz":-540,"elapsed":753,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"4813d8d9-096c-493f-9c87-d39c3b3058b8"},"source":["# iter, next를 이용해 일부 데이터를 확인할 수 있다.\n","dataiter = iter(trainloader)\n","images, labels = dataiter.next()\n","\n","#일반적으로 학습 데이터는 4차원 형태로 모델에서 사용된다.\n","# (배치크기) x (채널 수) x (너비) x (높이)\n","\n","print(images.size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["torch.Size([50, 3, 16, 16])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5Ueerxx0OhoX"},"source":["# 3.2 같은 클래스 별로 폴더를 정리한 경우"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wOVdUyFaPBbn","executionInfo":{"status":"ok","timestamp":1627880594842,"user_tz":-540,"elapsed":418,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"cbfb6d6d-0e23-465a-9240-e57de15fcbc6"},"source":["from google.colab import drive \n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":34},"id":"uqjTUuHlPqQY","executionInfo":{"status":"ok","timestamp":1627880600722,"user_tz":-540,"elapsed":8,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"dd911e7f-6fee-4216-b31e-4cb42e45af86"},"source":["pwd"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"gsNe_e-vPr5X"},"source":["!cd /content/gdrive/MyDrive/Pytorch"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lhGzcRi8GBOE"},"source":["# 데이터를 같은 클래스끼리 폴더를 미리 나눠줘야 됨 \n","# ex) class 폴더안에 tiger, lion 폴더를 각각 만든다 \n","\n","transf = tr.Compose([tr.Resize(128), tr.ToTensor()])\n","trainset=torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/Pytorch/class', transform=transf)\n","trainloader = DataLoader(trainset,batch_size=1, shuffle= True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RWjQPw-XToPh"},"source":["# 3.3 정형화 되지 않은 커스텀 데이터 불러오기(3.2 사용할 수 없을 때)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HKUvjsK6S8fa","executionInfo":{"status":"ok","timestamp":1627881756014,"user_tz":-540,"elapsed":370,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"b2da002a-ad6a-4ba8-c01f-66b901805705"},"source":["#32x32 컬러 이미지와 라벨이 각각 100장이 있다고 가정한다.\n","\n","train_images = np.random.randint(256,size=(100,32,32,3)) # 이미지 수 x 너비 x 높이 x 채널 수\n","train_labels = np.random.randint(2,size=(100,1)) #라벨 수 \n","\n","print(train_images.shape, train_labels.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(100, 32, 32, 3) (100, 1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"G-Gy68FST_KR"},"source":["# 양식!!! \n","'''\n","from torch.utils.data import Dataset\n","\n","class Mydataset(Dataset):\n","\n","  def __init__(Self):\n","  def __getitem__(self, index):\n","  def __len__(self):\n","'''\n","from torch.utils import Dataset\n","\n","class TensorData(Dataset):\n","\n","  def __init__(self,x_data, y_data):\n","    self.x_data = torch.FloatTensor(x_data) # 이미지 데이터를 FloatTensor로 변형 \n","    self.x_data = self.x_data.permute(0,3,1,2) # 이미지 수 x 너비 x 높이 x 채널수 >>>>> 배치크기 x 채널 수 x 너비 x 높이   ## 이렇게 차원 위치 바꿔준다\n","    self.y_data = torch.LongTensor(y_data) #라벨 데이터를 LongTensor로 변형\n","    self.len = self.y_data.shape[0] # 클래스 내의 들어 온 데이터 개수 \n","\n","  def __getitem__(self, index):\n","    return self.x_data[index], self.y_data[index] # 뽑아낼 데이터 적어준다 \n","\n","  def __len__(self):\n","    return self.len # 클래스 내에 들어 온 데이터 개수"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dXH5gELTa_Pz"},"source":["train_data = TensorData(train_images,train_labels)\n","train_loader = DataLoader(train_data, batch_size=10, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"E8kTij1cbpK0"},"source":["# 3.4 커스텀 데이터 + 커스텀 전처리 "]},{"cell_type":"code","metadata":{"id":"SGFlWAc1bRwh"},"source":["import torch \n","import torchvision.transforms as tr \n","from torch.utils.data import DataLoader, Dataset \n","import numpy as np "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8gQTpCRFb3YK"},"source":["# 32x32 이미지 100장 \n","train_images = np.random.randint(256, size= (100,32,32,3))\n","train_labels = np.random.randint(2,size=(100,1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YvH0iiloel2S","executionInfo":{"status":"ok","timestamp":1627885193729,"user_tz":-540,"elapsed":947,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}}},"source":["class TensorData(Dataset):\n","\n","  def __init__(self,x_data, y_data, transform= None):\n","    self.x_data = x_data # 이미지 데이터를 FloatTensor로 변형 \n","    self.y_data = y_data # 이미지 수 x 너비 x 높이 x 채널수 >>>>> 배치크기 x 채널 수 x 너비 x 높이   ## 이렇게 차원 위치 바꿔준다\n","    self.transform = transform\n","    self.len = len(y_data) # 클래스 내의 들어 온 데이터 개수 \n","\n","  def __getitem__(self, index):\n","    sample = self.x_data[index], self.y_data[index]\n","\n","    if self.transform: \n","      sample= self.transform(sample) #self.transform이 none이 아니라면 전처리 작업실행! \n","\n","\n","    return sample # 뽑아낼 데이터 적어준다 \n","\n","  def __len__(self):\n","    return self.len # 클래스 내에 들어 온 데이터 개수"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHo9hqJ9hMRN","executionInfo":{"status":"ok","timestamp":1627886336249,"user_tz":-540,"elapsed":377,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}}},"source":["# 전처리 기술을 직접 만들어보자 \n","# 위 기본 양식과 같이 사용하기 위해 call 함수를 사용한다 \n","# def __call__ 내의 원하는 전처리 작업을 프로그래밍 할 수 있다. \n","\n","# 1. 텐서변환 \n","class ToTensor:\n","  def __call__(self,sample):\n","    inputs, labels = sample\n","    inputs = torch.FloatTensor(inputs)\n","    inputs = inputs.permute(2,0,1)\n","    return inputs, torch.LongTensor(labels)\n","\n","# 2. 선형식\n","class LinearTensor: \n","\n","\n","  def __init__(self,slope=1, bias=0):\n","    self.slope = slope\n","    self.bias = bias\n","\n","  def __call__(self,sample):\n","    inputs,labels = sample\n","    inputs = self.slope*inputs + self.bias\n","    return inputs, labels\n"],"execution_count":40,"outputs":[]},{"cell_type":"code","metadata":{"id":"-WL9lqIPilcG","executionInfo":{"status":"ok","timestamp":1627886337764,"user_tz":-540,"elapsed":4,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}}},"source":["trans = tr.Compose([ToTensor(), LinearTensor(2,5)]) #텐서변환 후 선형식 2x+5 연산\n","dataset1 = TensorData(train_images, train_labels,transform=trans)\n","train_loader1 = DataLoader(dataset1,batch_size= 10, shuffle=True)\n"],"execution_count":41,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MozXX1wPjaxN","executionInfo":{"status":"ok","timestamp":1627886338151,"user_tz":-540,"elapsed":9,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}},"outputId":"2e3e0c96-c9a5-48e1-8cbb-28c2469b2b80"},"source":["dataiter1 = iter(train_loader1)\n","images1, labels1 = dataiter1.next()\n","print(images1.size())"],"execution_count":42,"outputs":[{"output_type":"stream","text":["torch.Size([10, 3, 32, 32])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"su4JEwFZluEM"},"source":["# 3.5 커스텀 데이터 + torchvision.transforms 전처리 "]},{"cell_type":"code","metadata":{"id":"otRd78K3k5B8","executionInfo":{"status":"ok","timestamp":1627886784517,"user_tz":-540,"elapsed":376,"user":{"displayName":"윤도현","photoUrl":"","userId":"02953559312839189387"}}},"source":["class MyTransform:\n","  \n","  def __call__(self, sample):\n","    inputs, labels = sample\n","    inputs = torch.FloatTensor(inputs)\n","    inputs = torch.permute(2,0,1) # call 함수는 이미지를 1장씩 불러와서 처리하므로 인덱스가 0,1,2 밖에 없다 \n","    labels = torch.FloatTensor(labels)\n","\n","    transf = tr.Compose([tr.ToPILImage(), tr.Resize(128), tr.ToTensor(), tr.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n","    final_output = transf(input)\n","\n","    return final_output, labels"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"TakiC4CFnQyf"},"source":["dataset2 = TensorData(train_images, train_labels, transform= MyTransform())\n","train_loader2 = DataLoader(dataset1)"],"execution_count":null,"outputs":[]}]}